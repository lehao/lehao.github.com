
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>linux下grep分析APACHE 服务器日志 命令集合 - 乐皓博客</title>
  <meta name="author" content="乐皓">

  
  <meta name="description" content="分析日志 1.分析日志文件下 2014-03-17 访问页面最高 的前20个 URL 并排序 cat cookie_log |grep '17/Mar/2014'| awk '{print $12}'|sort|uniq -c|sort -nr|head -20 2.获取访问最高的10个IP地址 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.ilehao.com/blog/2014/03/19/linux-apache-grep-log/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="乐皓博客" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">乐皓博客</a></h1>
  
    <h2>爱乐，爱皓，爱乐皓.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.ilehao.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">博客</a></li>
  <li><a href="/blog/archives">文章列表</a></li>
  <li><a href="/aboutme">关于Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">linux下grep分析APACHE 服务器日志 命令集合</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-03-19T14:54:00+08:00" pubdate data-updated="true">Mar 19<span>th</span>, 2014</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><h2>分析日志</h2>

<p>1.分析日志文件下 2014-03-17 访问页面最高 的前20个 URL 并排序</p>

<pre><code>cat cookie_log |grep '17/Mar/2014'| awk '{print $12}'|sort|uniq -c|sort -nr|head -20   
</code></pre>

<p>2.获取访问最高的10个IP地址  同时也可以按时间来查询</p>

<pre><code>cat cookie_log|awk '{print $1}'|sort|uniq -c|sort -nr|head -10    
</code></pre>

<p>3.列出传输最大的几个exe文件（分析下载站的时候常用）</p>

<pre><code>cat cookie_log |awk '($7~/\.exe/){print $10 " " $1 " " $4 " " $7}'|sort -nr|head -20    
</code></pre>

<p>4.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数</p>

<pre><code>cat cookie_log |awk '($10 &gt; 200000 &amp;&amp; $7~/\.exe/){print $7}'|sort -n|uniq -c|sort -nr|head -100    
</code></pre>

<p>5.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面</p>

<pre><code>cat cookie_log |awk '($7~/\.php/){print $NF " " $1 " " $4 " " $7}'|sort -nr|head -100    
</code></pre>

<p>6.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数</p>

<pre><code>cat cookie_log |awk '($NF &gt; 60 &amp;&amp; $7~/\.html/){print $7}'|sort -n|uniq -c|sort -nr|head -100   
</code></pre>

<p>7.列出传输时间超过 30 秒的文件</p>

<pre><code>cat cookie_log |awk '($NF &gt; 30){print $7}'|sort -n|uniq -c|sort -nr|head -20   
</code></pre>

<p>8.统计网站流量（G)</p>

<pre><code>cat cookie_log |awk '{sum+=$10} END {print sum/1024/1024/1024}'   
</code></pre>

<p>9.统计404的连接</p>

<pre><code>awk '($10 ~/404/)' cookie_log | awk '{print $10,$13}' | sort     
</code></pre>

<p>10.统计http status.</p>

<pre><code>cat cookie_log |awk '{counts[$(10)]+=1}; END {for(code in counts) print code, counts[code]}'  
cat cookie_log |awk '{print $10}'|sort|uniq -c|sort -rn   
</code></pre>

<p>11.每秒并发：</p>

<pre><code>awk '{if($10~/200|30|404/)COUNT[$5]++}END{for( a in COUNT) print a,COUNT[a]}'|sort -k 2 -nr|head -n10    
</code></pre>

<p>12.带宽统计</p>

<pre><code>cat apache.log |awk '{if($7~/GET/) count++}END{print "client_request="count}'   
cat apache.log |awk '{BYTE+=$11}END{print "client_kbyte_out="BYTE/1024"KB"}'    
</code></pre>

<p>13.找出某天访问次数最多的10个IP</p>

<pre><code>cat cookie_log | grep "17/Mar/2014" |awk '{print $3}'|sort |uniq -c|sort -nr|head   
</code></pre>

<p>14.当天ip连接数最高的ip都在干些什么:</p>

<pre><code>cat cookie_log | grep "10.0.21.17" | awk '{print $8}' | sort | uniq -c | sort -nr | head -n 10    
</code></pre>

<p>15.找出访问次数最多的几个分钟</p>

<pre><code>awk '{print $1}' cookie_log | grep "20/Mar/2011" |cut -c 14-18|sort|uniq -c|sort -nr|head   
</code></pre>

<h2>连接状态</h2>

<p>1.查看tcp连接状态:</p>

<pre><code>netstat -nat |awk '{print $6}'|sort|uniq -c|sort -rn
netstat -n | awk '/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}'
netstat -n | awk '/^tcp/ {++state[$NF]}; END {for(key in state) print key,"\t",state[key]}'
netstat -n | awk '/^tcp/ {++arr[$NF]};END {for(k in arr) print k,"\t",arr[k]}'
netstat -n |awk '/^tcp/ {print $NF}'|sort|uniq -c|sort -rn
netstat -ant | awk '{print $NF}' | grep -v '[a-z]' | sort | uniq -c
netstat -ant|awk '/ip:80/{split($5,ip,":");++S[ip[1]]}END{for (a in S) print S[a],a}' |sort -n
netstat -ant|awk '/:80/{split($5,ip,":");++S[ip[1]]}END{for (a in S) print S[a],a}' |sort -rn|head -n 10
awk 'BEGIN{printf ("http_code\tcount_num\n")}{COUNT[$10]++}END{for (a in COUNT) printf a"\t\t"COUNT[a]"\n"}'    
</code></pre>

<p>2.查找请求数请20个IP（常用于查找攻来源）：</p>

<pre><code>netstat -anlp|grep 80|grep tcp|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -nr|head -n20
netstat -ant |awk '/:80/{split($5,ip,":");++A[ip[1]]}END{for(i in A) print A[i],i}' |sort -rn|head -n20    
</code></pre>

<p>3.用tcpdump嗅探80端口的访问看看谁最高</p>

<pre><code>tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F"." '{print $1"."$2"."$3"."$4}' | sort | uniq -c | sort -nr |head -20    
</code></pre>

<p>4.查找较多time_wait连接</p>

<pre><code>netstat -n|grep TIME_WAIT|awk '{print $5}'|sort|uniq -c|sort -rn|head -n20    
</code></pre>

<p>5.找查较多的SYN连接</p>

<pre><code>netstat -an | grep SYN | awk '{print $5}' | awk -F: '{print $1}' | sort | uniq -c | sort -nr | more   
</code></pre>

<p>6.根据端口列进程</p>

<pre><code>netstat -ntlp | grep 80 | awk '{print $7}' | cut -d/ -f1   
</code></pre>

<h2>附 sort、uniq命令参数说明</h2>

<p>sort命令:</p>

<pre><code>表示逐行对指定文件中的所有行进行排序，并将结果显示在标准输出上。如果不指定文件或者使用“一”
表示文件，则排序内容来自标准输入。排序比较是依据从输入文件的每一行中提取的一个或多个排序关键字进
行的。排序关键字定义了用来排序的最小的字符序列。在默认情况下，排序关键字的顺序由系统使用的字符集
决定。
选项：
-m 对己经排好序的文件统一进行合并，但不做排序。
-c 检查给定的文件是否己排好序，若没有，则显示出错消息，不做排序。
-u与-c 选项一起用，严格地按顺序检查；否则，对排序后的重复行只输出第一行。
-o 文件名 将排序输出放到该文件名所指定的文件中。如果该文件不存在，则创建一个新文件。
改变排序规则的选项主要有：
-d 按字典顺序排序，比较时仅考虑空白符和字母数字符。
-f 忽略字母的大小写。
-i 忽略非打印字符。
-M 规定月份的比较次序是（未知）&lt;”JAN”&lt;”FEB”&lt;…&lt;”DEC”。 
-r 按逆序排序。默认排序输出是按升序排序的。
-k n1[,n2] 指定从文本行的第n1字段开始至第n2字段（不包括第n2字段）中间的内容作为排序关键字。如果没有n2，则关键字是从第n1个字段到行尾的所有字段。n1和n2可以是小数形式。如”x.y”，x表示第x字段，y表示第x字段中的第y个字符。字段和字符的文职都是从1开始算起的。
-b 比较关键字时忽略前导的空白符（空格或制表符）。
-t 字符将指定的“字符”作为字段间的分隔符。    
</code></pre>

<p>uniq命令：</p>

<pre><code>[选项] 文件
说明：uniq命令读取输入文件，并比较相邻的行，去掉重复的行一行。该命令加工后的结果写到输出文件中。
输入文件和输出文件必须不同。用“一”表示，则从标准输入上读取。选项：
-c 显示输出时，在每行的行首加上该行在文件中出现的次数。
-d 只显示重复行。
-f --skip-fields=N  忽略比较前N个字段。
-s --skip-chars=N 忽略比较前N个字段。
-u 只显示文件中不重复的行。
</code></pre>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">乐皓</span></span>

      








  


<time datetime="2014-03-19T14:54:00+08:00" pubdate data-updated="true">Mar 19<span>th</span>, 2014</time>
      


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/03/18/special-character/" title="Previous Post: 特殊字符的含义">&laquo; 特殊字符的含义</a>
      
      
        <a class="basic-alignment right" href="/blog/2014/03/21/string-intern/" title="Next Post: 我对String及String.intern()的理解">我对String及String.intern()的理解 &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p><img src="/images/blogImgs/self.jpg"></p>
  <p>java程序员，老猿人，孩子他爸</p>
  <p>爱篮球，爱Google, 爱折腾</p>
  <p>喜欢开源的东西, 喜欢读书和思考</p>
  <p><img src="/images/email.png"  alt="milehao@gmail.com" /></p>
</section>
<section>
  <h1>Sina 微博</h1>
<iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=3&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=2235818362&verifier=f873c807&dpc=1"></iframe>
</section><section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/03/27/thread-wait-sleep/">Thread.sleep()与Object.wait()的区别</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/21/string-intern/">我对String及String.intern()的理解</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/19/linux-apache-grep-log/">linux下grep分析APACHE 服务器日志 命令集合</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/18/special-character/">特殊字符的含义</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/04/idp/">2014个人发展计划(IDP)</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Tag Cloud</h1>
    <span id="tag-cloud"></span>
</section><section>
  <ul id="categories">
    
  </ul>
</section><section>
  <h1>最新评论</h1>
  <script type="text/javascript" src="http://lehao.disqus.com/recent_comments_widget.js?num_items=5&hide_avatars=0&avatar_size=32&excerpt_length=200"></script>
</section><section>
<h1>My Douban</h1>
<div>
<script type="text/javascript" src="http://www.douban.com/service/badge/ilehao/?show=wishlist&n=9&columns=3&hidelogo=yes&cat=movie|book" ></script>
</div>
</section>


  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - 乐皓 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script src="http://s21.cnzz.com/stat.php?id=4841109&web_id=4841109&show=pic" language="JavaScript"></script>
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43609148-1', 'ilehao.com');
  ga('send', 'pageview');

</script>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'lehao';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://www.ilehao.com/blog/2014/03/19/linux-apache-grep-log/';
        var disqus_url = 'http://www.ilehao.com/blog/2014/03/19/linux-apache-grep-log/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
